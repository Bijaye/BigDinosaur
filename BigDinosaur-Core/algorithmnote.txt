Update1:Every BigDinosaur Framework objects must possess BdCore characteristics
BdCore as main interface is finalized
Analyzing the pattern till now data structure takes 1 level branch of tree .
BFileRow and NTableNode classes can be considered for tree nodes .BfileRow has pointing reference to  NTableNode

Algorithm version 0.0
1 Start master node
2.Start Slaves node
3.Copy files from normal location of files to BDfilesystem.It exists in master node but has reference to all slave filesyetm.Say suppose exists 100 files
4.Read no of map value .Say suppose map=10.Then distribute 100/10 files into slave clusters.BdSlave class represent it.
5.File is distributed on locations slave cluster file system .It is part of BDDfs.
6.Processing starts on the basis of map reduce business logic 
7.Access to read and write is done via master .If client want to delete blocks ,read blocks i.e i.o operations then client access master and master calls slave 
8.Acl is applied on this session
9.Cluster is a group of slave and master nodes 
Impl
Capturing data
Curation
Storage
Searching
Sharing
Transfer
Analysis
Presentation

Impl Parts:
DNS round robin look on that as the part of request identify
.See reference image 


capabilities of platform 
BDFS over HTTP
1.provides a REST HTTP gateway to BDFS with full
filesystem read & write capabilities.

2.Must be able to browse the file bdfs from web .
For example:User is populated combo with file lineage or combo with blocks .But the file lineage is part of
big dinosaur file system and is distributed and only name node about its abstraction that is distributed on
data nodes
3.user must be able to see the view of data node and name nodes from browser .Like browse block ,browse directory
4.Browse distributed file system contents from web browser 
5.Browse dfs health status
6.Browse job history
7.Browse job details 
8.Browse job failues 
9.Browse job queue details
10.Browse job tasks
11.Browse job tasks history 
12.Browse job tracker 
13.Browse load history
14.Browse machines 
15.Browse task details 
16.Browse task detail history


later impl 


what hadoop has adopted
Kerberos SPNEGO for auth

BigDinosaur uses own Database system for file store integrated as core part of platform 
File read algorithm
  1 read from .data that exists on some directory
  2 Create BdFileNode object by reading every row .
  3 Every row represent BdFileNode
  
  Target Of processing 
  First:
 Data Size= 500 GB 
 Running Tasks:12000
 Seconds:
 Consideration:waste,reduce,merge,shuffle,maps
 
   Second:
 Data Size= PetaByte
 Running Tasks:35000
 Minutes:
 Consideration:waste,reduce,merge,shuffle,maps
 
  Data Size= TeraByte
 Running Tasks:12000
 Minutes:
 Consideration:waste,reduce,merge,shuffle,maps
 
   Data Size= 100TeraByte
 Running Tasks:30000
 Minutes:
 Consideration:waste,reduce,merge,shuffle,maps
 
 
 Must able to run under big dinosaur
 Knuth's dancing links algorithm 
 Bailey-Borwein-Plouffe to compute exact 
 * digits of Pi
 
 Examples it must solve 
 A map/reduce program that counts the words in the input files
 A map/reduce program that counts the average length of the words in the input files
 A map/reduce program that counts the median length of the words in the input files
 A map/reduce program that counts the standard deviation of the length of the words in the input files
 An Aggregate based map/reduce program that counts the words in the input files
 An Aggregate based map/reduce program that computes the histogram of the words in the input files
 A map/reduce program that counts the matches of a regex in the input
 A map/reduce program that writes 10GB of random data per node
 A map/reduce program that writes 10GB of random textual data per node
 A map/reduce program that sorts the data written by the random writer
 